{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetsNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "     -------------------------------------- 468.7/468.7 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.24.2-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     ---------------------------------------- 14.8/14.8 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-11.0.0-cp311-cp311-win_amd64.whl (20.5 MB)\n",
      "     ---------------------------------------- 20.5/20.5 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     -------------------------------------- 110.5/110.5 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp311-cp311-win_amd64.whl (11.2 MB)\n",
      "     ---------------------------------------- 11.2/11.2 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "     -------------------------------------- 134.3/134.3 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "     -------------------------------------- 154.0/154.0 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "     -------------------------------------- 317.2/317.2 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "     -------------------------------------- 200.1/200.1 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "     -------------------------------------- 143.2/143.2 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "     -------------------------------------- 96.7/96.7 kB 691.6 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp311-cp311-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.3/55.3 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     -------------------------------------- 502.3/502.3 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     -------------------------------------- 341.8/341.8 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, pyyaml, numpy, multidict, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, pyarrow, pandas, multiprocess, aiosignal, responses, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-22.2.0 certifi-2022.12.7 charset-normalizer-3.1.0 datasets-2.11.0 dill-0.3.6 filelock-3.11.0 frozenlist-1.3.3 fsspec-2023.4.0 huggingface-hub-0.13.4 idna-3.4 multidict-6.0.4 multiprocess-0.70.14 numpy-1.24.2 pandas-2.0.0 pyarrow-11.0.0 pytz-2023.3 pyyaml-6.0 requests-2.28.2 responses-0.18.0 tqdm-4.65.0 typing-extensions-4.5.0 tzdata-2023.3 urllib3-1.26.15 xxhash-3.2.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#importing datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/natal/.cache/huggingface/datasets/GonzaloA___parquet/GonzaloA--fake_news-1fe2b42e1fa111c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "#loading train dataset\n",
    "dataset_train = load_dataset(\"GonzaloA/fake_news\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/natal/.cache/huggingface/datasets/GonzaloA___parquet/GonzaloA--fake_news-1fe2b42e1fa111c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "#loading test dataset\n",
    "dataset_test = load_dataset(\"GonzaloA/fake_news\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/natal/.cache/huggingface/datasets/GonzaloA___parquet/GonzaloA--fake_news-1fe2b42e1fa111c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "#loading validation dataset \n",
    "dataset_validation = load_dataset(\"GonzaloA/fake_news\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting datasets into dataframes\n",
    "df_train = pd.DataFrame(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting datasets into dataframes\n",
    "df_test = pd.DataFrame(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting datasets into dataframes\n",
    "df_validate = pd.DataFrame(dataset_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed column\n",
    "df_train.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed column\n",
    "df_test.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed column\n",
    "df_validate.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns, dropping NAN values, and dropping the text column\n",
    "df = df_train.rename(columns={'title':'statement'})\n",
    "df = df.dropna(subset=['statement']).reset_index(drop=True)\n",
    "df = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Negation Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods for negating sentences\n",
    "negate_dict = {\" isn't \":\" is \",\n",
    "    \" isn\\'t \":\" is \",\n",
    "    \" is not \":\" is \",\n",
    "    \" is \":\" is not \",\n",
    "    \" didn't \":\" did \",\n",
    "    \" didn\\'t \":\" did \",\n",
    "    \" did not \":\" did \",\n",
    "    \" does not have \":\" has \",\n",
    "    \" doesn't have \":\" has \",\n",
    "    \" doesn\\'t have \":\" has \",\n",
    "    \" has \":\" does not have \",\n",
    "    \" shouldn't \":\" should \",\n",
    "    \" shouldn\\'t \":\" should \",\n",
    "    \" should not \":\" should \",\n",
    "    \" should \":\" should not \",\n",
    "    \" wouldn't \":\" would \",\n",
    "    \" wouldn\\'t \":\" would \",\n",
    "    \" would not \":\" would \",\n",
    "    \" would \":\" would not \",\n",
    "    \" mustn't \":\" must \",\n",
    "    \" mustn\\'t \":\" must \",\n",
    "    \" must not \":\" must \",\n",
    "    \" must \":\" must not \",\n",
    "    \" can't \":\" can \",\n",
    "    \" can\\'t \":\" can \",\n",
    "    \" cannot \":\" can \",\n",
    "    \" can \":\" cannot \"} \n",
    "\n",
    "IRREGULAR_ES_VERB_ENDINGS = [\"ss\", \"x\", \"ch\", \"sh\", \"o\"]\n",
    "\n",
    "def negate(sentence):\n",
    "\n",
    "  for key in negate_dict.keys():\n",
    "    if sentence.find(key) > -1:\n",
    "      return sentence.replace(key, negate_dict[key])\n",
    "\n",
    "\n",
    "\n",
    "  if re.search(\"doesn't\", sentence):\n",
    "    return re.sub(\"doesn't\", \"does not\", sentence, 1)\n",
    "\n",
    "  return None\n",
    "\n",
    "def __is_consonant(letter):\n",
    "  return letter not in ['a', 'e', 'i', 'o', 'u', 'y']\n",
    "\n",
    "\n",
    "def replace_verb(matchobj):\n",
    "  subject = matchobj.group(1)\n",
    "  verb = matchobj.group(2)\n",
    "  whitespace = matchobj.group(3)\n",
    "\n",
    "  if verb.endswith(\"y\") and __is_consonant(verb[-2]):\n",
    "        return \"{0}ies\".format(verb[0:-1])\n",
    "\n",
    "  # flies -> fly, but not die -> dy\n",
    "  if verb.endswith(\"ie\") and len(verb) > 3:\n",
    "    verb = \"{0}y\".format(verb[0:-2])\n",
    "\n",
    "  # stresses -> stress\n",
    "  for ending in IRREGULAR_ES_VERB_ENDINGS:\n",
    "        \n",
    "    if verb.endswith(ending):\n",
    "      return \"{0}es\".format(verb)    \n",
    "    elif verb.endswith(\"{0}e\".format(ending)):\n",
    "      verb = verb[0:-1]\n",
    "\n",
    "  return \"{0}{1}{2}\".format(subject, verb, whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['statement'] = df['statement'].apply(lambda x: x.lower().replace('’',\"'\"))\n",
    "df_neg = df.copy()\n",
    "df_neg['statement'] = df_neg['statement'].apply(negate)\n",
    "\n",
    "df_neg = df_neg.loc[~df_neg.statement.isnull()]\n",
    "df_pos = df.loc[df_neg.index].reset_index(drop=True)\n",
    "df_neg = df_neg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘maury' show official facebook posts f*cked u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump's favorite news channel tries to soothe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>russia warns iraq, kurds not to destabilize mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watch steve scalise throw a strike at the nati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump will hate what stephen colbert just did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>eu parliament chief asks poland to ensure meps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>chemical weapons watchdog found sarin used in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>melissa harris-perry is done with msnbc, pens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>trump's pick for navy secretary withdraws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>ukraine's tymoshenko expects fair u.s. ruling ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  label\n",
       "0       ‘maury' show official facebook posts f*cked u...      0\n",
       "1       trump's favorite news channel tries to soothe...      0\n",
       "2      russia warns iraq, kurds not to destabilize mi...      1\n",
       "3      watch steve scalise throw a strike at the nati...      0\n",
       "4       trump will hate what stephen colbert just did...      0\n",
       "...                                                  ...    ...\n",
       "24348  eu parliament chief asks poland to ensure meps...      1\n",
       "24349  chemical weapons watchdog found sarin used in ...      1\n",
       "24350   melissa harris-perry is done with msnbc, pens...      0\n",
       "24351          trump's pick for navy secretary withdraws      1\n",
       "24352  ukraine's tymoshenko expects fair u.s. ruling ...      1\n",
       "\n",
       "[24353 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu's verhofstadt pokes fun at british pm may b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>most unwanted man in the world: argentinians d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald trump jr. says bragging about sexual a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>china says war must be allowed on korean penin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in alabama's senate race, contenders fight ove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>hillary's secret weapon for the end of her ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>get out of jail free: how obama's race war is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>mike pence is not fine with trump sexual assau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>trump unravels as republicans admit he should...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>melissa harris-perry is not done with msnbc, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              statement  label\n",
       "0     eu's verhofstadt pokes fun at british pm may b...      1\n",
       "1     most unwanted man in the world: argentinians d...      0\n",
       "2      donald trump jr. says bragging about sexual a...      0\n",
       "3     china says war must be allowed on korean penin...      1\n",
       "4     in alabama's senate race, contenders fight ove...      1\n",
       "...                                                 ...    ...\n",
       "2980   hillary's secret weapon for the end of her ca...      0\n",
       "2981  get out of jail free: how obama's race war is ...      0\n",
       "2982  mike pence is not fine with trump sexual assau...      1\n",
       "2983   trump unravels as republicans admit he should...      0\n",
       "2984   melissa harris-perry is not done with msnbc, ...      0\n",
       "\n",
       "[2985 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.to_csv('C:/Users/natal/Documents/NLP/negated_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Reversal Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB 9.6 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.6/12.8 MB 7.6 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.7/12.8 MB 5.9 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.1/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.2/12.8 MB 5.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 5.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 3.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.0/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.2/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.8/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.1/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.7/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.0/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 9.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.3/12.8 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 11.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\natal\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\natal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entities(text, type='PERSON'):\n",
    "    doc = nlp(text)\n",
    "    return [entity.text for entity in doc.ents if (entity.label_==type)\\\n",
    "          and (len(entity.text.split())>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities['entities'] = df_entities['statement'].apply(find_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity = df_entities.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(set(list(itertools.chain(*df_entity['entities']))))\n",
    "df_pol = pd.DataFrame({'name':names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_names(text, lst1, lst2):\n",
    "    for (a,b) in zip(lst1,lst2):\n",
    "        text = text.replace(a,b)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_shuffled = shuffle(df_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of candidates\n",
    "df_entity['statement_new'] = df_entity.apply(lambda row: replace_names(row['statement'],row['entities'],list(df_pol_shuffled['name'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity.drop('statement',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity.drop('entities',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity.drop('random entity',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity.rename(columns={'statement_new':'statement'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘Maury’ Show Official Facebook Posts F*CKED U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump’s Favorite News Channel Tries To Soothe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russia warns Iraq, Kurds not to destabilize Mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH STEVE SCALISE Throw A Strike At The Nati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump Will HATE What Ruth Bader Just Did To H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>EU Parliament chief asks Poland to ensure MEPs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>Chemical weapons watchdog found sarin used in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>Ruth Bader Is DONE With MSNBC, Pens Detailed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>Trump's pick for Navy secretary withdraws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>Ukraine's Tymoshenko expects fair U.S. ruling ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  label\n",
       "0       ‘Maury’ Show Official Facebook Posts F*CKED U...      0\n",
       "1       Trump’s Favorite News Channel Tries To Soothe...      0\n",
       "2      Russia warns Iraq, Kurds not to destabilize Mi...      1\n",
       "3      WATCH STEVE SCALISE Throw A Strike At The Nati...      0\n",
       "4       Trump Will HATE What Ruth Bader Just Did To H...      0\n",
       "...                                                  ...    ...\n",
       "24348  EU Parliament chief asks Poland to ensure MEPs...      1\n",
       "24349  Chemical weapons watchdog found sarin used in ...      1\n",
       "24350   Ruth Bader Is DONE With MSNBC, Pens Detailed ...      0\n",
       "24351          Trump's pick for Navy secretary withdraws      1\n",
       "24352  Ukraine's Tymoshenko expects fair U.S. ruling ...      1\n",
       "\n",
       "[24353 rows x 2 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = ['statement','label']\n",
    "df_entity=df_entity.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity.to_csv('C:/Users/natal/Documents/NLP/name_switched_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adverb Intensity Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOSTER_DICT = ['absolutely', 'amazingly', 'awfully', 'barely',\n",
    "                'completely', 'considerably', 'decidedly', 'deeply', \n",
    "                'enormously', 'entirely', 'especially', 'exceptionally',\n",
    "                'exclusively', 'extremely', 'fully', 'greatly', 'hardly',\n",
    "                'hella', 'highly', 'hugely', 'incredibly', 'intensely',\n",
    "                'majorly', 'overwhelmingly', 'really', 'remarkably',\n",
    "                'substantially', 'thoroughly', 'totally', 'tremendously',\n",
    "                'unbelievably', 'unusually', 'utterly', 'very']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb['polar_word'] = df_adverb['statement'].apply(lambda s: any(w in BOOSTER_DICT for w in s.split())) \n",
    "df_adverb = df_adverb.loc[df_adverb.polar_word].reset_index(drop=True)\n",
    "df_adverb['statement_new'] = df_adverb['statement'].apply(lambda s: ' '.join([w for w in s.split() if w.lower() not in BOOSTER_DICT]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>polar_word</th>\n",
       "      <th>statement_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU's Mogherini: U.S. says will fully implement...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>EU's Mogherini: U.S. says will implement Iran ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wh press secretary says obamas denial about cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>wh press secretary says obamas denial about cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI INVESTIGATION Into HILLARY’S Email Server ...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>FBI INVESTIGATION Into HILLARY’S Email Server ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAXINE WATERS: Obama’s Left A “very, very powe...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>MAXINE WATERS: Obama’s Left A “very, powerful”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNBELIEVABLE! VINTAGE VIDEO EXPOSES Racist Fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>UNBELIEVABLE! VINTAGE VIDEO EXPOSES Racist Fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Trump says he is 'very, very close' to making ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Trump says he is 'very, close' to making Fed c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Vice President Pence: Trump greatly concern ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Vice President Pence: Trump concern about Irma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RUSSIA HITS OBAMA…HARD: “We are reaching a rea...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>RUSSIA HITS OBAMA…HARD: “We are reaching a ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>leaked emails reveal hillary cant speak for ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>leaked emails reveal hillary cant speak for lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NUMEROUS PUBLIC Rapes Of Teenage Girls Reporte...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NUMEROUS PUBLIC Rapes Of Teenage Girls Reporte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement  label  polar_word   \n",
       "0   EU's Mogherini: U.S. says will fully implement...      1        True  \\\n",
       "1   wh press secretary says obamas denial about cl...      1        True   \n",
       "2   FBI INVESTIGATION Into HILLARY’S Email Server ...      0        True   \n",
       "3   MAXINE WATERS: Obama’s Left A “very, very powe...      0        True   \n",
       "4   UNBELIEVABLE! VINTAGE VIDEO EXPOSES Racist Fir...      0        True   \n",
       "..                                                ...    ...         ...   \n",
       "56  Trump says he is 'very, very close' to making ...      1        True   \n",
       "57  Vice President Pence: Trump greatly concern ab...      1        True   \n",
       "58  RUSSIA HITS OBAMA…HARD: “We are reaching a rea...      0        True   \n",
       "59  leaked emails reveal hillary cant speak for ve...      0        True   \n",
       "60  NUMEROUS PUBLIC Rapes Of Teenage Girls Reporte...      0        True   \n",
       "\n",
       "                                        statement_new  \n",
       "0   EU's Mogherini: U.S. says will implement Iran ...  \n",
       "1   wh press secretary says obamas denial about cl...  \n",
       "2   FBI INVESTIGATION Into HILLARY’S Email Server ...  \n",
       "3   MAXINE WATERS: Obama’s Left A “very, powerful”...  \n",
       "4   UNBELIEVABLE! VINTAGE VIDEO EXPOSES Racist Fir...  \n",
       "..                                                ...  \n",
       "56  Trump says he is 'very, close' to making Fed c...  \n",
       "57  Vice President Pence: Trump concern about Irma...  \n",
       "58  RUSSIA HITS OBAMA…HARD: “We are reaching a ter...  \n",
       "59  leaked emails reveal hillary cant speak for lo...  \n",
       "60  NUMEROUS PUBLIC Rapes Of Teenage Girls Reporte...  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb.drop('polar_word',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb.drop('statement',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb.rename(columns={'statement_new':'statement'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = ['statement','label']\n",
    "df_adverb=df_adverb.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverb.to_csv('C:/Users/natal/Documents/NLP/adverb_intensity_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b31755cbf75356c393a3522367cd288f0b05170e2bd292c75b11fc3d2da2cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
